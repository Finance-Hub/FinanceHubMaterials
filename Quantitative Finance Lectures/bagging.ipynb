{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging in backtesting\n",
    "\n",
    "#### by Gustavo Soares\n",
    "\n",
    "In this notebook you will apply a few things you learned in the [FinanceHub's Python lectures](https://github.com/Finance-Hub/FinanceHubMaterials/tree/master/Python%20Lectures) as well as in the [FinanceHub's Quantitative Finance Lectures](https://github.com/Finance-Hub/FinanceHubMaterials/tree/master/Quantitative%20Finance%20Lectures). In particular, we will take use what we have learned about the [Bootstrap](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/bootstrap_in_finance.ipynb).\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The [Bootstrap](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/bootstrap_in_finance.ipynb) is used in many situations in which it is hard or even impossible to directly compute the standard deviation of a quantity of interest. However, it is an extremely powerful tool for prediction as well.\n",
    "\n",
    "Often time, prediction methods suffer from high variance and low accuracy. This means that if we split the training data into two parts at random, and fit a decision tree to both halves, the results that we get could be quite different. **Bootstrap aggregation**, or **bagging**, is a general-purpose procedure for reducing the bagging variance of a statistical learning method. It is particularly useful and frequently used in the context of [decision trees](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/tree_based_methods_in_fx.ipynb).\n",
    "\n",
    "Let's get started by importing a few things and get right away to an example.\n",
    "\n",
    "### FX trading example\n",
    "\n",
    "Here we will use the example of FX trading to illustrate how to use bagging for predictions. We have discussed previously the three main types of signals in FX trading:\n",
    "[carry](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/carry.ipynb), [momentum](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/time_series_momentum.ipynb) and [value](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/ppp_value_in_fx.ipynb). So, let's start by getting the data on these three types of signals.\n",
    "\n",
    "For each signal $s$ for $s \\in \\{carry,momentum,value\\}$ we have a value $x_{s,i,t}$ containing the signal $s$ for currency $i$ at time $t$ already appropriately lagged. Remember, that we need to make sure $x_{s,i,t}$ is only using information that was available at the time of trading to predict h-period returns from time $t$ to some time in the future $t+h$. So, the value $x_{s,i,t}$ needs to be calculated using information prior to $t$. Here, we lag the information set by one period and calculate $x_{s,i,t}$ only with information contained in $\\mathscr{I}_{t-1}$.\n",
    "\n",
    "We also discussed how to construct [FX trackers](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/creating_fx_time_series_fh.ipynb) for each currency against the USD. Here, we will just upload the data on the FX trackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carry data has 24 currencies and 4973 dates\n",
      "momentum data has 24 currencies and 4968 dates\n",
      "value data has 24 currencies and 4973 dates\n",
      "trackers data has 24 currencies and 5220 dates\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "carry_df = pd.read_excel(r'fx_trackers_and_signals.xlsx',sheet_name='carry',index_col=0)\n",
    "print('carry data has %s currencies and %s dates' % (carry_df.shape[1],carry_df.shape[0]))\n",
    "mom_df = pd.read_excel(r'fx_trackers_and_signals.xlsx',sheet_name='momentum',index_col=0)\n",
    "print('momentum data has %s currencies and %s dates' % (mom_df.shape[1],mom_df.shape[0]))\n",
    "value_df = pd.read_excel(r'fx_trackers_and_signals.xlsx',sheet_name='value',index_col=0)\n",
    "print('value data has %s currencies and %s dates' % (value_df.shape[1],value_df.shape[0]))\n",
    "trackers_df = pd.read_excel(r'fx_trackers_and_signals.xlsx',sheet_name='trackers',index_col=0)\n",
    "print('trackers data has %s currencies and %s dates' % (trackers_df.shape[1],trackers_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable we want to predict is\n",
    "$$\n",
    "r_{i,t+h} \\equiv \\frac{I_{t+h}}{I_{t}}-1\n",
    "$$\n",
    "\n",
    "which contains the returns of currency $i$ over the period between $t$ and $t+h$ as measured by the percentage change in the the currency tracker level $I_{t}$ over the period. This assumes that we traded at level $I_{t}$ at inception and closed the position $I_{t+h}$. Let's use `Pandas` to create a dataframe containing these returns for $h=21$ business days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns data has 24 currencies and 2241 dates\n"
     ]
    }
   ],
   "source": [
    "h = 21\n",
    "# note the use of the .shift(-h) method below to make sure that on the index t we have the returns from t to t+h\n",
    "returns_df = trackers_df.pct_change(h).shift(-h).dropna()\n",
    "print('returns data has %s currencies and %s dates' % (returns_df.shape[1],returns_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling the data\n",
    "\n",
    "Let's start by poolling the data. That is we create a set of variables we want to predict:\n",
    "\n",
    "$$\n",
    "y_{i,t} = r_{i,t+h}\n",
    "$$\n",
    "\n",
    "and a $3 \\times 1$ vector of signals containing the signals for currency $i$ at time $t$, $X_{i,t} = [x_{carry,i,t},x_{momentum,i,t},x_{value,i,t}]'$. This vector $X_{i,t}$ will be used to predict the future returns $y_{i,t} = r_{i,t+h}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dict = dict(zip([ccy for ccy in returns_df.columns],range(len(returns_df.columns))))\n",
    "groups = pd.DataFrame()\n",
    "pooled_data = pd.DataFrame()\n",
    "for ccy in returns_df.columns:\n",
    "    # get future returns\n",
    "    y = returns_df[ccy].to_frame('returns')\n",
    "    # get the three signals\n",
    "    X_carry = carry_df[ccy].dropna().to_frame('carry')\n",
    "    X_mom = mom_df[ccy].dropna().to_frame('mom')\n",
    "    X_value = value_df[ccy].dropna().to_frame('value')\n",
    "    # make sure the signals are lined up and fill the nan's with the last obs in case there are some\n",
    "    X = pd.concat([X_carry,X_mom,X_value],join='outer',axis=1,sort=True).fillna(method='ffill').dropna()\n",
    "    \n",
    "    Z = (X-X.shift(1).ewm(halflife=63).mean())/X.shift(1).ewm(halflife=63).std()\n",
    "    # make sure the dates of the signals and future returns line up\n",
    "    yZ = pd.concat([y,Z],axis=1,sort=True).dropna()\n",
    "    \n",
    "    pooled_data = pooled_data.append(yZ)\n",
    "    \n",
    "    group = pd.DataFrame(index=yZ.index,columns=['group'],data=group_dict[ccy])\n",
    "    groups = groups.append(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of only using the three signals, $[x_{carry,i,t},x_{momentum,i,t},x_{value,i,t}]'$ for prediction, let's also use their interactions and squares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>carry</th>\n",
       "      <th>mom</th>\n",
       "      <th>value</th>\n",
       "      <th>carry^2</th>\n",
       "      <th>carry mom</th>\n",
       "      <th>carry value</th>\n",
       "      <th>mom^2</th>\n",
       "      <th>mom value</th>\n",
       "      <th>value^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.217493</td>\n",
       "      <td>-0.215423</td>\n",
       "      <td>-0.511210</td>\n",
       "      <td>1.482290</td>\n",
       "      <td>-0.262276</td>\n",
       "      <td>-0.622394</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>0.110126</td>\n",
       "      <td>0.261335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.854565</td>\n",
       "      <td>-0.174336</td>\n",
       "      <td>-0.595210</td>\n",
       "      <td>0.730281</td>\n",
       "      <td>-0.148982</td>\n",
       "      <td>-0.508645</td>\n",
       "      <td>0.030393</td>\n",
       "      <td>0.103767</td>\n",
       "      <td>0.354275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.565515</td>\n",
       "      <td>-0.402217</td>\n",
       "      <td>-0.304515</td>\n",
       "      <td>0.319807</td>\n",
       "      <td>-0.227460</td>\n",
       "      <td>-0.172208</td>\n",
       "      <td>0.161779</td>\n",
       "      <td>0.122481</td>\n",
       "      <td>0.092729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.570330</td>\n",
       "      <td>-0.461571</td>\n",
       "      <td>-0.407267</td>\n",
       "      <td>0.325276</td>\n",
       "      <td>-0.263248</td>\n",
       "      <td>-0.232276</td>\n",
       "      <td>0.213048</td>\n",
       "      <td>0.187983</td>\n",
       "      <td>0.165866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909194</td>\n",
       "      <td>-0.302033</td>\n",
       "      <td>-0.515772</td>\n",
       "      <td>0.826633</td>\n",
       "      <td>-0.274606</td>\n",
       "      <td>-0.468936</td>\n",
       "      <td>0.091224</td>\n",
       "      <td>0.155780</td>\n",
       "      <td>0.266020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1     carry       mom     value   carry^2  carry mom  \\\n",
       "2011-01-18  1.0  1.217493 -0.215423 -0.511210  1.482290  -0.262276   \n",
       "2011-01-19  1.0  0.854565 -0.174336 -0.595210  0.730281  -0.148982   \n",
       "2011-01-20  1.0  0.565515 -0.402217 -0.304515  0.319807  -0.227460   \n",
       "2011-01-21  1.0  0.570330 -0.461571 -0.407267  0.325276  -0.263248   \n",
       "2011-01-24  1.0  0.909194 -0.302033 -0.515772  0.826633  -0.274606   \n",
       "\n",
       "            carry value     mom^2  mom value   value^2  \n",
       "2011-01-18    -0.622394  0.046407   0.110126  0.261335  \n",
       "2011-01-19    -0.508645  0.030393   0.103767  0.354275  \n",
       "2011-01-20    -0.172208  0.161779   0.122481  0.092729  \n",
       "2011-01-21    -0.232276  0.213048   0.187983  0.165866  \n",
       "2011-01-24    -0.468936  0.091224   0.155780  0.266020  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = PolynomialFeatures()\n",
    "X.fit_transform(pooled_data.iloc[:,1:])\n",
    "features_names = X.get_feature_names(pooled_data.columns[1:])\n",
    "X = X.fit_transform(pooled_data.iloc[:,1:])\n",
    "X = pd.DataFrame(index=pooled_data.index,data=X,columns=features_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we predicting future returns $y_{i,t} = r_{i,t+h}$ with the  $X_{i,t}$ but using a second-order polinomial instad of simply using a simple linear function.\n",
    "\n",
    "### Current state\n",
    "\n",
    "Suppose I observe the following vector $X_{i,T}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.268358  , -0.112417  ,  0.212429  ,  0.07201602,\n",
       "         0.030168  , -0.05700702,  0.01263758, -0.02388063,  0.04512608]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_signal = -0.268358\n",
    "m_signal = -0.112417\n",
    "v_signal = 0.212429\n",
    "X0 = PolynomialFeatures()\n",
    "X0 = X0.fit_transform([[c_signal,m_signal,v_signal]])\n",
    "X0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with a Support Vector Classifier\n",
    "\n",
    "Support vector classifiers (SVC) is a popular technique for classification. SVCs have been shown to perform well in a variety of settings, and are often considered one of the best “out of the box” classifiers. SVC performs particularly well relative to other methods when we have high dimensional spaces. SVCs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation. A good discusion on SVM can be found in Chapter 9 of [James, Witten, Hastie, and Tibshirani (2013)](http://faculty.marshall.usc.edu/gareth-james/ISL/).  Let's use the [support vector machines package in scikit-learn](https://scikit-learn.org/stable/modules/svm.html#svm-classification) to carry out the SVC predictions as we have discussed in our [previous lecture](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/classifiers_fx_example.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "y = np.sign(pooled_data.iloc[:,0])\n",
    "clf.fit(X,y)\n",
    "clf.predict([X0.squeeze()])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the full sample, the SVC is predicting a bear (-1) market in the currency $i$ if its current features are given by the vector $X_{i,T}$.\n",
    "\n",
    "### Predicting with a Decision Tree\n",
    "\n",
    "As we have discussed in a [previous lecture](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/tree_based_methods_in_fx.ipynb), similarly to SVCs, decision trees are constructed by stratifying or segmenting the predictor space into a number of simple regions. In order to make a prediction for a given observation, we typically use the mean or the mode of the training observations in the region to which it belongs. Since the set of splitting rules used to segment the predictor space can be summarized in a tree, these types of approaches are known as decision tree methods Tand are simple and useful for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=4)\n",
    "tree_clf = tree_clf.fit(X, y)\n",
    "tree_clf.predict([X0.squeeze()])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the full sample, the Decision Tree is also predicting a bear (-1) market in the currency $i$ if its current features are given by the vector $X_{i,T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "We have seen leave-one-out cross-validation (LOOCV) in a [previous lecture](https://github.com/Finance-Hub/FinanceHubMaterials/blob/master/Quantitative%20Finance%20Lectures/cross_validation_in_fx.ipynb). Here, we use it to create $N=24$ (as many as we have currencies) training sets. Each learning set is created by taking all the markets except one, the test set being the market left out. After the entire process, we will have trained $N$ models, as many models as there are markets or currencies.\n",
    "\n",
    "For each training set we will a prediction for future returns $\\hat{y}_{k,T}$ of currency $i$ given the features vector $X_{i,T}$, one for each trainning set $k$. **Bagging** or **Bootstrap aggregation** consists in taking the average prediction across the different training sets:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{bag,T} = N^{-1}\\sum_{k=1}^{N}\\hat{y}_{k,T}\n",
    "$$\n",
    "\n",
    "There are three main advantages of using bagging for forecasting:\n",
    "\n",
    "1. In practice, we know that it greatly improves prediction accuracy of a statistical learning method. Bagging has been demonstrated to give impressive improvements in accuracy, particularly for decision trees, by combining together hundreds or even thousands of predictions into a single procedure.\n",
    "2. Averaging a set of predictions reduces variance of the predictions so the predictions are more stable across different samples, in particular, the predictions do not completly change as new information becomes available\n",
    "3. Instead of running a model in the full sample, since we are running the model in several independent samples, we can run each bootstrap prediction in parallel, in a seperate CPU using [multiprocessing](https://docs.python.org/2/library/multiprocessing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(groups=groups)\n",
    "results_df = pd.DataFrame()\n",
    "for train_index, test_index in logo.split(X, y, groups.iloc[:,0]):\n",
    "    \n",
    "    group_results = pd.Series(index=['SVC_prediction','SVC_groups_acc','Tree_prediction','Tree_groups_acc'],data=0.)\n",
    "    \n",
    "    clf.fit(X,y)\n",
    "    group_results['SVC_prediction'] = clf.predict([X0.squeeze()])[0]\n",
    "    group_results['SVC_groups_acc'] = (1*(clf.predict(X.iloc[test_index])==y.iloc[test_index])).mean()\n",
    "                                \n",
    "    tree_clf = tree_clf.fit(X, y)\n",
    "    group_results['Tree_prediction'] = tree_clf.predict([X0.squeeze()])[0]    \n",
    "    group_results['Tree_groups_acc'] = (1*(tree_clf.predict(X.iloc[test_index])==y.iloc[test_index])).mean()\n",
    "                                           \n",
    "    results_df = results_df.append(group_results.to_frame(groups.iloc[test_index[0],0]).T)                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that now we have two predictions for each trainning set $k$. One prediction $\\hat{y}_{k,T}$ coming from the SVC model and another $\\tilde{y}_{k,T}$ coming from the decision tree model. We also have how they performed in terms of accuracy in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC_prediction</th>\n",
       "      <th>SVC_groups_acc</th>\n",
       "      <th>Tree_prediction</th>\n",
       "      <th>Tree_groups_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.569389</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.532352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.579206</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.543507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.531013</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.515395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.554663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.564926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.586345</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.536814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.570710</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.593357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.585899</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.568496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.595716</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.574297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.631415</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.644801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.556448</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.543507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.565819</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.587238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.539045</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.506024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.549308</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.531013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.491745</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.511379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.592146</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.549308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.574743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.569835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.513164</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.509148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.596609</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.546185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.519411</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.533244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.554663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.567604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.528782</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.507809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.551986</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.590808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.533244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.545292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SVC_prediction  SVC_groups_acc  Tree_prediction  Tree_groups_acc\n",
       "0             -1.0        0.569389             -1.0         0.532352\n",
       "1             -1.0        0.579206             -1.0         0.543507\n",
       "2             -1.0        0.531013             -1.0         0.515395\n",
       "3             -1.0        0.554663             -1.0         0.564926\n",
       "4             -1.0        0.586345             -1.0         0.536814\n",
       "5             -1.0        0.570710             -1.0         0.593357\n",
       "6             -1.0        0.585899             -1.0         0.568496\n",
       "7             -1.0        0.595716             -1.0         0.574297\n",
       "8             -1.0        0.631415             -1.0         0.644801\n",
       "9             -1.0        0.556448             -1.0         0.543507\n",
       "10            -1.0        0.565819             -1.0         0.587238\n",
       "11            -1.0        0.539045             -1.0         0.506024\n",
       "12            -1.0        0.549308             -1.0         0.531013\n",
       "13            -1.0        0.491745             -1.0         0.511379\n",
       "14            -1.0        0.592146             -1.0         0.549308\n",
       "15            -1.0        0.574743             -1.0         0.569835\n",
       "16            -1.0        0.513164             -1.0         0.509148\n",
       "17            -1.0        0.596609             -1.0         0.546185\n",
       "18            -1.0        0.519411             -1.0         0.533244\n",
       "19            -1.0        0.554663             -1.0         0.567604\n",
       "20            -1.0        0.528782             -1.0         0.507809\n",
       "21            -1.0        0.551986             -1.0         0.590808\n",
       "22            -1.0        0.530120             -1.0         0.533244\n",
       "23            -1.0        0.520750             -1.0         0.545292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the simple bagging prediction with SVC: -1.0\n",
      "This is the simple bagging prediction with DT: -1.0\n",
      "This is the weighted bagging prediction with SVC: -1.0\n",
      "This is the weighted bagging prediction with Tree: -1.0\n",
      "This is the weighted bagging prediction with Tree + SVC combined: -1.0\n"
     ]
    }
   ],
   "source": [
    "print('This is the simple bagging prediction with SVC: %s' % results_df['SVC_prediction'].mean())\n",
    "print('This is the simple bagging prediction with DT: %s' % results_df['Tree_prediction'].mean())\n",
    "acc_weights = results_df['SVC_groups_acc']/results_df['SVC_groups_acc'].sum()\n",
    "weighted_SVC = results_df['SVC_prediction']*acc_weights\n",
    "print('This is the weighted bagging prediction with SVC: %s' % weighted_SVC.sum())\n",
    "acc_weights = results_df['Tree_groups_acc']/results_df['Tree_groups_acc'].sum()\n",
    "weighted_tree = results_df['Tree_prediction']*acc_weights\n",
    "print('This is the weighted bagging prediction with Tree: %s' % weighted_tree.sum())\n",
    "model_combination = (weighted_SVC+weighted_tree)/2\n",
    "print('This is the weighted bagging prediction with Tree + SVC combined: %s' % model_combination.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above are not exactly predictions, they are averages of -1 and 1 predictions. So, to predict a quantitative outcome for $y_{i,T} = r_{i,T+h}$ we typically take a **majority vote** approach by making the overall prediction is the most commonly occurring majority class among the predictions. In our case, this would be a bull market (1) if the bagging prediction was positive and a bear market (-1) if the bagging prediction was negative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
